{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kennethsee/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/kennethsee/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.similarities import MatrixSimilarity\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import, merge, and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import patient and video data into dataframes\n",
    "df_patient = pd.read_csv('./Data/patient_info_CONFIDENTIAL.csv')\n",
    "df_video = pd.read_csv('./Data/video_watched_events_CONFIDENTIAL.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename datetime_created column names\n",
    "df_video = df_video.rename(columns={'datetime_created':'datetime_created_video'})\n",
    "df_patient = df_patient.rename(columns={'datetime_created':'datetime_created_patient'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age categories are mapped as follow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Age Category | Lower Bound | Upper Bound |\n",
    "| --- | --- | --- |\n",
    "| GIGeneration | 93 | 119 |\n",
    "| SilentGeneration | 75 | 92 |\n",
    "| Boomers | 56 | 74 |\n",
    "| GenX | 40 | 55 |\n",
    "| Millenials | 24 | 39 |\n",
    "| GenZ | 8 | 23 |\n",
    "| GenAlpha | 0 | 7 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map age categories\n",
    "def age_mapper(age):\n",
    "    '''\n",
    "    Takes in an age as an integer and maps it to the respective age category\n",
    "    '''\n",
    "    age_cat = \"\"\n",
    "    \n",
    "    if 93 <= age <= 119:\n",
    "        age_cat = \"GIGeneration\"\n",
    "    elif 75 <= age <= 92:\n",
    "        age_cat = \"SilentGeneration\"\n",
    "    elif 56 <= age <= 74:\n",
    "        age_cat = \"Boomers\"\n",
    "    elif 40 <= age <= 55:\n",
    "        age_cat = \"GenX\"\n",
    "    elif 24 <= age <= 39:\n",
    "        age_cat = \"Millenials\"\n",
    "    elif 8 <= age <= 23:\n",
    "        age_cat = \"GenZ\"\n",
    "    elif 0 <= age <= 7:\n",
    "        age_cat = \"GenAlpha\"\n",
    "    else: # handle edge cases\n",
    "        age_cat = \"\"\n",
    "    \n",
    "    return age_cat\n",
    "\n",
    "df_patient['age_category'] = df_patient['age'].apply(age_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EDA for viewer activeness\n",
    "df_patient['viewer_activeness_ratio'] = df_patient['total_activities_done']/df_patient['unique_days_with_activity']\n",
    "print(df_patient['viewer_activeness_ratio'].hist(bins=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewer Activeness Ratio is classified as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Lowest Number of Videos Watched (per day) | Most Number of Videos Watched (per day) | Activeness Category |\n",
    "| --- | --- | --- |\n",
    "| 0 | 1.99 | Inactive |\n",
    "| 2 | 3.99 | Sedentary |\n",
    "| 4 | 5.99 | Light |\n",
    "| 6 | 7.99 | Moderate |\n",
    "| 8 | 9.99 | Active |\n",
    "| 10 | 11.99 | Vigorous |\n",
    "| 12 | above | Very Vigorous |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map viewer activeness category\n",
    "def activeness_mapper(ratio):\n",
    "    \n",
    "    cat = ''\n",
    "    \n",
    "    if ratio < 2:\n",
    "        cat = 'Inactive'\n",
    "    elif 2 <= ratio < 4:\n",
    "        cat = 'Sedentary'\n",
    "    elif 4 <= ratio < 6:\n",
    "        cat = 'Light'\n",
    "    elif 6 <= ratio < 8:\n",
    "        cat = 'Moderate'\n",
    "    elif 8 <= ratio < 10:\n",
    "        cat = 'Active'\n",
    "    elif 10 <= ratio < 12:\n",
    "        cat = 'Vigorous'\n",
    "    else:\n",
    "        cat = 'Very Vigorous'\n",
    "        \n",
    "    return cat\n",
    "\n",
    "df_patient['activeness_category'] = df_patient['viewer_activeness_ratio'].apply(activeness_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video['tags'] = df_video['tags'].replace(np.nan, '[\\'\\']')\n",
    "df_video['tags'] = df_video['tags'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove numbers and websites\n",
    "def no_number_and_website_preprocessor(tokens):\n",
    "    r = re.sub(r'\\d+', '', str(tokens))\n",
    "    r = re.sub(r'http\\S+', '', r)\n",
    "    return r\n",
    "\n",
    "df_video['notes'] = df_video['notes'].apply(no_number_and_website_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_created_video</th>\n",
       "      <th>id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>homework_id</th>\n",
       "      <th>subsection_watched_from</th>\n",
       "      <th>url</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>secondary_category</th>\n",
       "      <th>notes</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>length</th>\n",
       "      <th>notes_and_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-20 12:09:40.503569</td>\n",
       "      <td>50948</td>\n",
       "      <td>26207</td>\n",
       "      <td>624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Featured</td>\n",
       "      <td>https://www.youtube.com/watch?v=CxVsxOH0yGA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>Why Uncertainty Sucks (and how to deal with it)</td>\n",
       "      <td>Get the first 30 days of Curiosity Stream free...</td>\n",
       "      <td>brain braincraft brain craft psychology uncert...</td>\n",
       "      <td>466</td>\n",
       "      <td>why uncertainty sucks (and how to deal with it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-13 04:11:27.120579</td>\n",
       "      <td>38875</td>\n",
       "      <td>26207</td>\n",
       "      <td>620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Featured</td>\n",
       "      <td>https://www.youtube.com/watch?v=0AIEqUq6q1U</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>['Sleep']</td>\n",
       "      <td>Why We Worry So Much</td>\n",
       "      <td>http://www.cloudlessmind.com - Why do we worry...</td>\n",
       "      <td>Paul Smit Scott Byrd Advaita Nonduality Change...</td>\n",
       "      <td>137</td>\n",
       "      <td>why we worry so much paul smit scott byrd adva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-22 12:31:55.011380</td>\n",
       "      <td>42215</td>\n",
       "      <td>26207</td>\n",
       "      <td>620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recently Watched</td>\n",
       "      <td>https://www.youtube.com/watch?v=0AIEqUq6q1U</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>['Sleep']</td>\n",
       "      <td>Why We Worry So Much</td>\n",
       "      <td>http://www.cloudlessmind.com - Why do we worry...</td>\n",
       "      <td>Paul Smit Scott Byrd Advaita Nonduality Change...</td>\n",
       "      <td>137</td>\n",
       "      <td>why we worry so much paul smit scott byrd adva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-13 04:30:36.606531</td>\n",
       "      <td>27614</td>\n",
       "      <td>26207</td>\n",
       "      <td>787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Featured</td>\n",
       "      <td>https://www.youtube.com/watch?v=fAjdI7J4Gvo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>Science-Backed Ways to Relieve Stress Right Now!</td>\n",
       "      <td>To support our channel and level up your healt...</td>\n",
       "      <td>relieve stress how to relieve stress stress re...</td>\n",
       "      <td>285</td>\n",
       "      <td>science-backed ways to relieve stress right n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-03 11:37:00.498739</td>\n",
       "      <td>24201</td>\n",
       "      <td>26207</td>\n",
       "      <td>771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Featured</td>\n",
       "      <td>https://youtu.be/otFrNM7PnME?t=3</td>\n",
       "      <td>Cognitive Behavioral Therapy</td>\n",
       "      <td>['Depression', 'Anxiety', 'Stress', 'Managing ...</td>\n",
       "      <td>Cognitive Distortions</td>\n",
       "      <td>A person's thoughts and beliefs—whether they'r...</td>\n",
       "      <td>cbt psychotherapy cognitive distortions therap...</td>\n",
       "      <td>305</td>\n",
       "      <td>cognitive distortions cbt psychotherapy cognit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime_created_video     id  patient_id  video_id  homework_id  \\\n",
       "0  2020-03-20 12:09:40.503569  50948       26207       624          NaN   \n",
       "1  2020-02-13 04:11:27.120579  38875       26207       620          NaN   \n",
       "2  2020-02-22 12:31:55.011380  42215       26207       620          NaN   \n",
       "3  2020-01-13 04:30:36.606531  27614       26207       787          NaN   \n",
       "4  2020-01-03 11:37:00.498739  24201       26207       771          NaN   \n",
       "\n",
       "  subsection_watched_from                                          url  \\\n",
       "0                Featured  https://www.youtube.com/watch?v=CxVsxOH0yGA   \n",
       "1                Featured  https://www.youtube.com/watch?v=0AIEqUq6q1U   \n",
       "2        Recently Watched  https://www.youtube.com/watch?v=0AIEqUq6q1U   \n",
       "3                Featured  https://www.youtube.com/watch?v=fAjdI7J4Gvo   \n",
       "4                Featured             https://youtu.be/otFrNM7PnME?t=3   \n",
       "\n",
       "               primary_category  \\\n",
       "0                           NaN   \n",
       "1                       Anxiety   \n",
       "2                       Anxiety   \n",
       "3                           NaN   \n",
       "4  Cognitive Behavioral Therapy   \n",
       "\n",
       "                                  secondary_category  \\\n",
       "0                                               ['']   \n",
       "1                                          ['Sleep']   \n",
       "2                                          ['Sleep']   \n",
       "3                                               ['']   \n",
       "4  ['Depression', 'Anxiety', 'Stress', 'Managing ...   \n",
       "\n",
       "                                               notes  \\\n",
       "0    Why Uncertainty Sucks (and how to deal with it)   \n",
       "1                               Why We Worry So Much   \n",
       "2                               Why We Worry So Much   \n",
       "3   Science-Backed Ways to Relieve Stress Right Now!   \n",
       "4                              Cognitive Distortions   \n",
       "\n",
       "                                         description  \\\n",
       "0  Get the first 30 days of Curiosity Stream free...   \n",
       "1  http://www.cloudlessmind.com - Why do we worry...   \n",
       "2  http://www.cloudlessmind.com - Why do we worry...   \n",
       "3  To support our channel and level up your healt...   \n",
       "4  A person's thoughts and beliefs—whether they'r...   \n",
       "\n",
       "                                                tags  length  \\\n",
       "0  brain braincraft brain craft psychology uncert...     466   \n",
       "1  Paul Smit Scott Byrd Advaita Nonduality Change...     137   \n",
       "2  Paul Smit Scott Byrd Advaita Nonduality Change...     137   \n",
       "3  relieve stress how to relieve stress stress re...     285   \n",
       "4  cbt psychotherapy cognitive distortions therap...     305   \n",
       "\n",
       "                                      notes_and_tags  \n",
       "0  why uncertainty sucks (and how to deal with it...  \n",
       "1  why we worry so much paul smit scott byrd adva...  \n",
       "2  why we worry so much paul smit scott byrd adva...  \n",
       "3   science-backed ways to relieve stress right n...  \n",
       "4  cognitive distortions cbt psychotherapy cognit...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine notes and tags\n",
    "def combine_list(lst):\n",
    "    return ' '.join(lst)\n",
    "\n",
    "df_video['tags'] = df_video['tags'].apply(combine_list)\n",
    "df_video['notes_and_tags'] = df_video['notes'] + ' ' + df_video['tags']\n",
    "\n",
    "# make lower case\n",
    "df_video['notes_and_tags'] = df_video['notes_and_tags'].str.lower()\n",
    "\n",
    "df_video.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize wordnet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize words\n",
    "df_video['notes_and_tags'] = df_video['notes_and_tags'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize words\n",
    "def lemmatize_list_of_words(words):\n",
    "    new_list = []\n",
    "    for word in words:\n",
    "        new_list.append(lemmatizer.lemmatize(word))\n",
    "    return new_list\n",
    "\n",
    "df_video['notes_and_tags'] = df_video['notes_and_tags'].apply(lemmatize_list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join back words to string\n",
    "df_video['notes_and_tags'] = df_video['notes_and_tags'].apply(combine_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit into topical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance of Counter Vectorizer\n",
    "cv = CountVectorizer(max_df = 0.90, min_df = 2, stop_words = 'english')\n",
    "\n",
    "# fit and transform text data\n",
    "cv_fit = cv.fit_transform(df_video['notes_and_tags'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=20, random_state=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create instance for LDA\n",
    "lda = LatentDirichletAllocation(n_components = 20, random_state = 1)\n",
    "\n",
    "# fit the LDA\n",
    "lda.fit(cv_fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 words in topic 0\n",
      "----------\n",
      "['mindfulness', 'meditation', 'breathing'] \n",
      "\n",
      "Top 3 words in topic 1\n",
      "----------\n",
      "['cognitive', 'automatic', 'thought'] \n",
      "\n",
      "Top 3 words in topic 2\n",
      "----------\n",
      "['management', 'smart', 'goal'] \n",
      "\n",
      "Top 3 words in topic 3\n",
      "----------\n",
      "['guided', 'meditation', 'sleep'] \n",
      "\n",
      "Top 3 words in topic 4\n",
      "----------\n",
      "['emotional', 'dimension', 'wellness'] \n",
      "\n",
      "Top 3 words in topic 5\n",
      "----------\n",
      "['neuroflow', 'mental', 'health'] \n",
      "\n",
      "Top 3 words in topic 6\n",
      "----------\n",
      "['video', 'motivational', 'purpose'] \n",
      "\n",
      "Top 3 words in topic 7\n",
      "----------\n",
      "['anxiety', 'china', 'coronavirus'] \n",
      "\n",
      "Top 3 words in topic 8\n",
      "----------\n",
      "['minute', 'health', 'pain'] \n",
      "\n",
      "Top 3 words in topic 9\n",
      "----------\n",
      "['major', 'depressive', 'disorder'] \n",
      "\n",
      "Top 3 words in topic 10\n",
      "----------\n",
      "['positive', 'meditation', 'psychology'] \n",
      "\n",
      "Top 3 words in topic 11\n",
      "----------\n",
      "['mental', 'health', 'therapy'] \n",
      "\n",
      "Top 3 words in topic 12\n",
      "----------\n",
      "['attack', 'stress', 'anxiety'] \n",
      "\n",
      "Top 3 words in topic 13\n",
      "----------\n",
      "['brain', 'skill', 'depression'] \n",
      "\n",
      "Top 3 words in topic 14\n",
      "----------\n",
      "['2019', 'health', 'coronavirus'] \n",
      "\n",
      "Top 3 words in topic 15\n",
      "----------\n",
      "['smart', 'geelong', 'sleep'] \n",
      "\n",
      "Top 3 words in topic 16\n",
      "----------\n",
      "['sleeping', 'sleep', 'yoga'] \n",
      "\n",
      "Top 3 words in topic 17\n",
      "----------\n",
      "['grounding', 'anxiety', 'music'] \n",
      "\n",
      "Top 3 words in topic 18\n",
      "----------\n",
      "['fibromyalgia', 'life', 'speech'] \n",
      "\n",
      "Top 3 words in topic 19\n",
      "----------\n",
      "['opioids', 'opioid', 'ted'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature = cv.get_feature_names()\n",
    "\n",
    "topic_map = {}\n",
    "\n",
    "for ind, topic in enumerate(lda.components_):\n",
    "    print(f'Top 3 words in topic {ind}')\n",
    "    print('-'*10)\n",
    "    top_3 = topic.argsort()[-3:]\n",
    "    topic_words = [feature[i] for i in top_3]\n",
    "    print(topic_words, '\\n')\n",
    "    # add to topic map\n",
    "    topic_map[ind] = topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign topics to df\n",
    "df_final = lda.transform(cv_fit)\n",
    "df_video['topic'] = df_final.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_created_video</th>\n",
       "      <th>id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>homework_id</th>\n",
       "      <th>subsection_watched_from</th>\n",
       "      <th>url</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>secondary_category</th>\n",
       "      <th>notes</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>length</th>\n",
       "      <th>notes_and_tags</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-20 12:09:40.503569</td>\n",
       "      <td>50948</td>\n",
       "      <td>26207</td>\n",
       "      <td>624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Featured</td>\n",
       "      <td>https://www.youtube.com/watch?v=CxVsxOH0yGA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>Why Uncertainty Sucks (and how to deal with it)</td>\n",
       "      <td>Get the first 30 days of Curiosity Stream free...</td>\n",
       "      <td>brain braincraft brain craft psychology uncert...</td>\n",
       "      <td>466</td>\n",
       "      <td>why uncertainty suck ( and how to deal with it...</td>\n",
       "      <td>13</td>\n",
       "      <td>[brain, skill, depression]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-13 04:11:27.120579</td>\n",
       "      <td>38875</td>\n",
       "      <td>26207</td>\n",
       "      <td>620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Featured</td>\n",
       "      <td>https://www.youtube.com/watch?v=0AIEqUq6q1U</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>['Sleep']</td>\n",
       "      <td>Why We Worry So Much</td>\n",
       "      <td>http://www.cloudlessmind.com - Why do we worry...</td>\n",
       "      <td>Paul Smit Scott Byrd Advaita Nonduality Change...</td>\n",
       "      <td>137</td>\n",
       "      <td>why we worry so much paul smit scott byrd adva...</td>\n",
       "      <td>5</td>\n",
       "      <td>[neuroflow, mental, health]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-22 12:31:55.011380</td>\n",
       "      <td>42215</td>\n",
       "      <td>26207</td>\n",
       "      <td>620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recently Watched</td>\n",
       "      <td>https://www.youtube.com/watch?v=0AIEqUq6q1U</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>['Sleep']</td>\n",
       "      <td>Why We Worry So Much</td>\n",
       "      <td>http://www.cloudlessmind.com - Why do we worry...</td>\n",
       "      <td>Paul Smit Scott Byrd Advaita Nonduality Change...</td>\n",
       "      <td>137</td>\n",
       "      <td>why we worry so much paul smit scott byrd adva...</td>\n",
       "      <td>5</td>\n",
       "      <td>[neuroflow, mental, health]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-13 04:30:36.606531</td>\n",
       "      <td>27614</td>\n",
       "      <td>26207</td>\n",
       "      <td>787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Featured</td>\n",
       "      <td>https://www.youtube.com/watch?v=fAjdI7J4Gvo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>Science-Backed Ways to Relieve Stress Right Now!</td>\n",
       "      <td>To support our channel and level up your healt...</td>\n",
       "      <td>relieve stress how to relieve stress stress re...</td>\n",
       "      <td>285</td>\n",
       "      <td>science-backed way to relieve stress right now...</td>\n",
       "      <td>12</td>\n",
       "      <td>[attack, stress, anxiety]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-03 11:37:00.498739</td>\n",
       "      <td>24201</td>\n",
       "      <td>26207</td>\n",
       "      <td>771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Featured</td>\n",
       "      <td>https://youtu.be/otFrNM7PnME?t=3</td>\n",
       "      <td>Cognitive Behavioral Therapy</td>\n",
       "      <td>['Depression', 'Anxiety', 'Stress', 'Managing ...</td>\n",
       "      <td>Cognitive Distortions</td>\n",
       "      <td>A person's thoughts and beliefs—whether they'r...</td>\n",
       "      <td>cbt psychotherapy cognitive distortions therap...</td>\n",
       "      <td>305</td>\n",
       "      <td>cognitive distortion cbt psychotherapy cogniti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[cognitive, automatic, thought]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime_created_video     id  patient_id  video_id  homework_id  \\\n",
       "0  2020-03-20 12:09:40.503569  50948       26207       624          NaN   \n",
       "1  2020-02-13 04:11:27.120579  38875       26207       620          NaN   \n",
       "2  2020-02-22 12:31:55.011380  42215       26207       620          NaN   \n",
       "3  2020-01-13 04:30:36.606531  27614       26207       787          NaN   \n",
       "4  2020-01-03 11:37:00.498739  24201       26207       771          NaN   \n",
       "\n",
       "  subsection_watched_from                                          url  \\\n",
       "0                Featured  https://www.youtube.com/watch?v=CxVsxOH0yGA   \n",
       "1                Featured  https://www.youtube.com/watch?v=0AIEqUq6q1U   \n",
       "2        Recently Watched  https://www.youtube.com/watch?v=0AIEqUq6q1U   \n",
       "3                Featured  https://www.youtube.com/watch?v=fAjdI7J4Gvo   \n",
       "4                Featured             https://youtu.be/otFrNM7PnME?t=3   \n",
       "\n",
       "               primary_category  \\\n",
       "0                           NaN   \n",
       "1                       Anxiety   \n",
       "2                       Anxiety   \n",
       "3                           NaN   \n",
       "4  Cognitive Behavioral Therapy   \n",
       "\n",
       "                                  secondary_category  \\\n",
       "0                                               ['']   \n",
       "1                                          ['Sleep']   \n",
       "2                                          ['Sleep']   \n",
       "3                                               ['']   \n",
       "4  ['Depression', 'Anxiety', 'Stress', 'Managing ...   \n",
       "\n",
       "                                               notes  \\\n",
       "0    Why Uncertainty Sucks (and how to deal with it)   \n",
       "1                               Why We Worry So Much   \n",
       "2                               Why We Worry So Much   \n",
       "3   Science-Backed Ways to Relieve Stress Right Now!   \n",
       "4                              Cognitive Distortions   \n",
       "\n",
       "                                         description  \\\n",
       "0  Get the first 30 days of Curiosity Stream free...   \n",
       "1  http://www.cloudlessmind.com - Why do we worry...   \n",
       "2  http://www.cloudlessmind.com - Why do we worry...   \n",
       "3  To support our channel and level up your healt...   \n",
       "4  A person's thoughts and beliefs—whether they'r...   \n",
       "\n",
       "                                                tags  length  \\\n",
       "0  brain braincraft brain craft psychology uncert...     466   \n",
       "1  Paul Smit Scott Byrd Advaita Nonduality Change...     137   \n",
       "2  Paul Smit Scott Byrd Advaita Nonduality Change...     137   \n",
       "3  relieve stress how to relieve stress stress re...     285   \n",
       "4  cbt psychotherapy cognitive distortions therap...     305   \n",
       "\n",
       "                                      notes_and_tags  topic  \\\n",
       "0  why uncertainty suck ( and how to deal with it...     13   \n",
       "1  why we worry so much paul smit scott byrd adva...      5   \n",
       "2  why we worry so much paul smit scott byrd adva...      5   \n",
       "3  science-backed way to relieve stress right now...     12   \n",
       "4  cognitive distortion cbt psychotherapy cogniti...      1   \n",
       "\n",
       "                       topic_words  \n",
       "0       [brain, skill, depression]  \n",
       "1      [neuroflow, mental, health]  \n",
       "2      [neuroflow, mental, health]  \n",
       "3        [attack, stress, anxiety]  \n",
       "4  [cognitive, automatic, thought]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map topic words\n",
    "df_video['topic_words'] = df_video['topic'].map(topic_map)\n",
    "df_video.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean primary and secondary category columns\n",
    "df_video['primary_category'] = df_video['primary_category'].replace(np.nan,'')\n",
    "df_video['secondary_category'] = df_video['secondary_category'].replace(np.nan, '[\\'\\']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert secondary category to list\n",
    "df_video['secondary_category'] = df_video['secondary_category'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training dataframe\n",
    "# initialize dictionary and list\n",
    "patient_dict = {}\n",
    "list_of_key_words = []\n",
    "\n",
    "# iterate through patient df\n",
    "for i, row in df_patient.iterrows():\n",
    "    #reset list of key words\n",
    "    list_of_key_words = []\n",
    "\n",
    "    # get this patient's patient id\n",
    "    patient_id = row['patient_id']\n",
    "    \n",
    "    # add patient's sex\n",
    "    list_of_key_words.append(row['sex'].lower())\n",
    "    \n",
    "    # add patient's age category\n",
    "    list_of_key_words.append(row['age_category'])\n",
    "    \n",
    "    # add patient's viewer activeness category\n",
    "    list_of_key_words.append(row['activeness_category'])\n",
    "\n",
    "    # search through video df\n",
    "    for j, video_row in df_video[df_video['patient_id'] == patient_id].iterrows():\n",
    "        # append words in primary and secondary category to list of key words\n",
    "        if video_row['primary_category'] != '':\n",
    "            list_of_key_words.append(video_row['primary_category'].lower())\n",
    "        for word in video_row['secondary_category']:\n",
    "            if word != '':\n",
    "                list_of_key_words.append(word.lower())\n",
    "\n",
    "        for topic in video_row['topic_words']:\n",
    "            list_of_key_words.append(topic)\n",
    "\n",
    "    # add entry to patient dictionary\n",
    "    patient_dict[patient_id] = list_of_key_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>key_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26207</td>\n",
       "      <td>[female, GenX, Light, brain, skill, depression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26208</td>\n",
       "      <td>[male, Boomers, Inactive, neuroflow, mental, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26209</td>\n",
       "      <td>[male, Boomers, Light, brain, skill, depressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26211</td>\n",
       "      <td>[female, GenX, Moderate, anxiety, brain, skill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26212</td>\n",
       "      <td>[male, Millenials, Inactive, managing pain, fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id                                          key_words\n",
       "0       26207  [female, GenX, Light, brain, skill, depression...\n",
       "1       26208  [male, Boomers, Inactive, neuroflow, mental, h...\n",
       "2       26209  [male, Boomers, Light, brain, skill, depressio...\n",
       "3       26211  [female, GenX, Moderate, anxiety, brain, skill...\n",
       "4       26212  [male, Millenials, Inactive, managing pain, fi..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert patient dictionary to training dataframe\n",
    "df_train = pd.DataFrame(list(patient_dict.items()), columns=['patient_id', 'key_words'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will be using cosine similarity to get the closest patients to the patient given based on scraped keywords.\n",
    "We then get the ranked videos that each of the closest patients watched based on frequency of watching, then recommend\n",
    "the highest 3 ranked videos that the patient given has not already watched.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model to Find Closest Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of words\n",
    "list_of_key_words = df_train['key_words'].to_list()\n",
    "dictionary = Dictionary(list_of_key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create genism corpus\n",
    "corpus = [dictionary.doc2bow(doc) for doc in list_of_key_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert corpus into tf-idf model\n",
    "tfidf = TfidfModel(corpus)\n",
    "\n",
    "# get similarity\n",
    "sims = MatrixSimilarity(tfidf[corpus], num_features = len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get similar patients\n",
    "def patient_recommendation(patient_id):\n",
    "    '''\n",
    "    Takes in a patient ID and recommends all the closest patients. Closest patients are determined by cosine similarity\n",
    "    with a score of at least 0.85.\n",
    "    '''\n",
    "    # get patient row\n",
    "    patient = df_train.loc[df_train['patient_id'] == patient_id]\n",
    "    \n",
    "    # get keywords\n",
    "    key_words = patient['key_words'].iloc[0]\n",
    "    query_doc = key_words\n",
    " \n",
    "    # get bag of words and convert into model\n",
    "    query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "    query_doc_tfidf = tfidf[query_doc_bow]\n",
    "    \n",
    "    # get similarity array\n",
    "    similarity_array = sims[query_doc_tfidf]\n",
    "    \n",
    "    # arrange results by top matching\n",
    "    similarity_series = pd.Series(similarity_array.tolist(), index=df_train['patient_id'].values)\n",
    "    top_recs = similarity_series.sort_values(ascending=False)[1::] # exclude self\n",
    "    \n",
    "    # return list of recommendations\n",
    "#     sorted_tfidf_weights = sorted(tfidf[corpus[df_test.index.values.tolist()[0]]], key=lambda w:w[1], reverse=True)\n",
    "    rec = []\n",
    "    for id, (patient, score) in enumerate(zip(top_recs.index, top_recs)):\n",
    "        # only add if score >= 0.85\n",
    "        if score >= 0.85:\n",
    "            rec.append((patient, score))\n",
    "        \n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE PATIENT THAT RECOMMENDATION WOULD BE MADE FOR\n",
    "# note: chosen patient ID must exist in the patient database\n",
    "rec_patient_id = 26207 # REPLACE ID HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following patients are closest to patient 26207:\n",
      "Patient 56343 with a closeness of 89.33%\n",
      "Patient 26925 with a closeness of 88.12%\n",
      "Patient 63051 with a closeness of 85.93%\n",
      "Patient 66733 with a closeness of 85.63%\n",
      "Patient 66287 with a closeness of 85.01%\n"
     ]
    }
   ],
   "source": [
    "# Get recommended patients\n",
    "recommendation = patient_recommendation(rec_patient_id)\n",
    "\n",
    "print('The following patients are closest to patient ' + str(rec_patient_id) + ':')\n",
    "for rec in recommendation:\n",
    "    print('Patient ' + str(rec[0]) + ' with a closeness of ' + str(round(rec[1] * 100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this block to check accuracy of prediction\n",
    "# recommended_patient_id = 37620 # CHANGE THIS ID BASED ON PATIENTS RETURNED FROM PATIENT RECOMMENDER\n",
    "\n",
    "# print('Key words for patient ' + str(rec_patient_id))\n",
    "# print(df_train[df_train['patient_id'] == rec_patient_id].key_words.iloc[0])\n",
    "# print('\\n')\n",
    "# print('Key words for patient ' + str(recommended_patient_id))\n",
    "# print(df_train[df_train['patient_id'] == recommended_patient_id].key_words.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Video Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final step, we first obtain all the videos watched by the recommended patients and consolidate the total times each video is watched among them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create top videos by patient dictionary\n",
    "top_videos_by_patient_dict = {}\n",
    "video_frequency = {}\n",
    "top_5_videos = []\n",
    "\n",
    "# iterate through patient df\n",
    "for i, row in df_patient.iterrows():\n",
    "    #reset video frequency and top 5 videos\n",
    "    video_frequency = {}\n",
    "    top_5_videos = []\n",
    "\n",
    "    # get this patient's patient id\n",
    "    patient_id = row['patient_id']\n",
    "\n",
    "    # iterrate through videos\n",
    "    for j, video_row in df_video[df_video['patient_id'] == patient_id].iterrows(): \n",
    "\n",
    "        # get video id\n",
    "        video_id = video_row['video_id']\n",
    "\n",
    "        # check if video id already exists in video frequency dictionary\n",
    "        if video_id in video_frequency:\n",
    "            # increment frequency if video already exists in dictionary\n",
    "            video_frequency[video_id] += 1\n",
    "        else: # video does not yet exist in dictionary\n",
    "            # create a new key value pair with key as video and value as 1\n",
    "            video_frequency[video_id] = 1\n",
    "\n",
    "    # find top 5 most watched videos\n",
    "    counter = Counter(video_frequency)\n",
    "    top_videos_counter = counter.most_common(5)\n",
    "    for video in top_videos_counter:\n",
    "        this_video_id = video[0] # get id\n",
    "        this_video_freq = video[1] # get number of times it was watched\n",
    "        temp_tuple = (this_video_id, this_video_freq) # bring both of them together into a tuple\n",
    "        # append tuple to top 5 videos list\n",
    "        top_5_videos.append(temp_tuple)\n",
    "\n",
    "    # add patient id and top 5 videos to top videos by patient dictionary\n",
    "    top_videos_by_patient_dict[patient_id] = top_5_videos\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top videos among all the close patients and their cumulative frequency\n",
    "top_videos = {}\n",
    "for rec in recommendation:\n",
    "    patient_id = rec[0]\n",
    "    \n",
    "    # get top 5 videos watched for this patient\n",
    "    top_videos_watched = top_videos_by_patient_dict[patient_id]\n",
    "    \n",
    "    for video in top_videos_watched:\n",
    "        vid_id = video[0]\n",
    "        frequency = video[1]\n",
    "    \n",
    "        # if video already exists in top videos dictionary, add to current frequency\n",
    "        if vid_id in top_videos:\n",
    "            top_videos[vid_id] += frequency\n",
    "        # if it does not yet exist in top videos dictionary, create new key value pair with video id as key and frequency\n",
    "        # as value\n",
    "        else:\n",
    "            top_videos[vid_id] = frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we remove any videos that the patient we are recommending to has watched within the past 6 months. This is to ensure that the patient is not recommended videos that he/she has already recently watched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kennethsee/opt/anaconda3/envs/aihacks2020/lib/python3.7/site-packages/ipykernel_launcher.py:40: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n"
     ]
    }
   ],
   "source": [
    "# remove any videos that the patient we are recommending to has already watched within the past 6 months\n",
    "def subtract_6_months_from_datetime_string(datetime_str):\n",
    "    year = datetime_str[0:4]\n",
    "    month = datetime_str[5:7]\n",
    "    rest_of_datetime = datetime_str[7::]\n",
    "    \n",
    "    if month in ['07', '08', '09', '10', '11', '12']:\n",
    "        if month == '07':\n",
    "            month = '01'\n",
    "        elif month == '08':\n",
    "            month = '02'\n",
    "        elif month == '09':\n",
    "            month = '03'\n",
    "        elif month == '10':\n",
    "            month = '04'\n",
    "        elif month == '11':\n",
    "            month = '05'\n",
    "        elif month == '12':\n",
    "            month = '06'\n",
    "    elif month in ['01', '02', '03', '04', '05', '06']:\n",
    "        # reduce year by 1\n",
    "        year = str(int(year) - 1)\n",
    "        \n",
    "        if month == '01':\n",
    "            month = '07'\n",
    "        elif month == '02':\n",
    "            month = '08'\n",
    "        elif month == '03':\n",
    "            month = '09'\n",
    "        elif month == '04':\n",
    "            month = '10'\n",
    "        elif month == '05':\n",
    "            month = '11'\n",
    "        elif month == '06':\n",
    "            month = '12'\n",
    "            \n",
    "    return year + '-' + month + rest_of_datetime\n",
    "    \n",
    "# get today's date as string\n",
    "today = pd.datetime.now().date().strftime('%Y-%m-%d')\n",
    "# get date six months ago\n",
    "six_month_ago_str = subtract_6_months_from_datetime_string(today)\n",
    "six_month_ago = pd.to_datetime(six_month_ago_str)\n",
    "\n",
    "# get all the videos that patient to recommend to has watched in the past six months\n",
    "videos_watched_last_6_months = df_video[(df_video['patient_id'] == rec_patient_id) & (df_video['datetime_created_video'].apply(pd.to_datetime) > six_month_ago)]\n",
    "\n",
    "# remove identified videos from top videos dictionary\n",
    "for key in [key for key in top_videos if videos_watched_last_6_months['video_id'].isin([key]).any()]: del top_videos[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we rank the remaining top videos and recommend the top 3 videos to the patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************************************************************************\n",
      "\n",
      "\n",
      "Here are your top video recommendations:\n",
      "\n",
      "1. Video 648 with the url https://www.youtube.com/watch?v=m2zRA5zCA6M\n",
      "2. Video 771 with the url https://youtu.be/otFrNM7PnME?t=3\n",
      "3. Video 612 with the url https://www.youtube.com/watch?v=z3H_GgtE3Tc\n",
      "\n",
      "\n",
      "**************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Rank the top videos and get top 3\n",
    "top_video_counter = Counter(top_videos)\n",
    "top3 = top_video_counter.most_common(3)\n",
    "\n",
    "# Display recommendations\n",
    "print('*' * 110)\n",
    "print('\\n')\n",
    "if len(top3) != 0:\n",
    "    print('Here are your top video recommendations:\\n')\n",
    "    for i in range(len(top3)):\n",
    "        # video url\n",
    "        url = df_video[df_video['video_id'] == top3[i][0]]['url'].iloc[0]\n",
    "        print(str(i+1) + '. Video ' + str(top3[i][0]) + ' with the url ' + url)\n",
    "else:\n",
    "    print('Sorry, we are not able to recommend any videos at this moment.')\n",
    "print('\\n')\n",
    "print('*' * 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
